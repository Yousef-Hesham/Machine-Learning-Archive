{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torch\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "\n",
    "class GraphConv(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "       \n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, hid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.gconv1 = GraphConv(nfeat, hid)\n",
    "        self.gconv2 = GraphConv(hid, hid)\n",
    "        self.dropout = dropout\n",
    "        self.fc = nn.Linear(hid, nclass)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gconv1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gconv2(x, adj)\n",
    "  \n",
    "        x=self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features:\n",
      " tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "\n",
      "Adjacency matrix:\n",
      " tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n",
    "adj_matrix = torch.Tensor([[[1, 1, 0, 0],\n",
    "                            [1, 1, 1, 1],\n",
    "                            [0, 1, 1, 1],\n",
    "                            [0, 1, 1, 1]]])\n",
    "\n",
    "print(\"Node features:\\n\", node_feats)\n",
    "print(\"\\nAdjacency matrix:\\n\", adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9284, -0.5029],\n",
       "        [-1.2041, -0.3566],\n",
       "        [-1.0035, -0.4566],\n",
       "        [-1.0035, -0.4566]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "    \n",
    "model = GCN(nfeat=2 ,\n",
    "            hid=16,\n",
    "            nclass=2,\n",
    "            dropout=0.5)\n",
    "\n",
    "model(node_feats.squeeze(0),adj_matrix.squeeze(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl import DGLGraph\n",
    "from dgl.data import citation_graph as citegrh\n",
    "import networkx as nx\n",
    "\n",
    "def load_cora_data():\n",
    "    data = citegrh.load_cora()\n",
    "    features = torch.FloatTensor(data.features)\n",
    "    labels = torch.LongTensor(data.labels)\n",
    "    mask = torch.BoolTensor(data.train_mask)\n",
    "    g = data[0]\n",
    "    return g, features, labels, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.g = g\n",
    "        # equation (1)\n",
    "        self.fc = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        # equation (2)\n",
    "        self.attn_fc = nn.Linear(2 * out_dim, 1, bias=False)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_fc.weight, gain=gain)\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        # edge UDF for equation (2)\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
    "        #print('z2', z2.shape)\n",
    "        a = self.attn_fc(z2)\n",
    "        #print('a', a.shape)\n",
    "        return {'e': F.leaky_relu(a)}\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        # message UDF for equation (3) & (4)\n",
    "        return {'z': edges.src['z'], 'e': edges.data['e']}\n",
    "                    #source nodes features ||  edge features\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        # reduce UDF for equation (3) & (4)\n",
    "        # equation (3)\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
    "        #print(nodes.mailbox['e'].shape)\n",
    "       \n",
    "        # equation (4)\n",
    "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
    "        #print(h.shape)\n",
    "        return {'h': h}\n",
    "\n",
    "    def forward(self, h):\n",
    "        # equation (1)\n",
    "        z = self.fc(h)\n",
    "        #print('z',z.shape)\n",
    "        self.g.ndata['z'] = z\n",
    "        # equation (2)\n",
    "        self.g.apply_edges(self.edge_attention)\n",
    "        # equation (3) & (4)\n",
    "        self.g.update_all(self.message_func, self.reduce_func)\n",
    "        return self.g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "g, features, labels, mask = load_cora_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2708, num_edges=10556,\n",
       "      ndata_schemes={'feat': Scheme(shape=(1433,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 7])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1= GATLayer(g,\n",
    "               features.size()[1],\n",
    "               out_dim=7)\n",
    "\n",
    "\n",
    "net1(features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim, num_heads, merge='cat'):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GATLayer(g, in_dim, out_dim))\n",
    "        self.merge = merge\n",
    "\n",
    "    def forward(self, h):\n",
    "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
    "        #print(head_outs[0].shape)\n",
    "        if self.merge == 'cat':\n",
    "            # concat on the output feature dimension (dim=1)\n",
    "            return torch.cat(head_outs, dim=1)\n",
    "        else:\n",
    "            # merge using average\n",
    "            return torch.mean(torch.stack(head_outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer(g, in_dim, hidden_dim, num_heads)\n",
    "        # Be aware that the input dimension is hidden_dim*num_heads since\n",
    "        # multiple head outputs are concatenated together. Also, only\n",
    "        # one attention head in the output layer.\n",
    "        self.layer2 = MultiHeadGATLayer(g, hidden_dim * num_heads, out_dim, 1)\n",
    "\n",
    "    def forward(self, h):\n",
    "        h = self.layer1(h)\n",
    "    \n",
    "        h = F.elu(h)\n",
    "        h = self.layer2(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/dgl/data/utils.py:288: UserWarning: Property dataset.feat will be deprecated, please use g.ndata['feat'] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/dgl/data/utils.py:288: UserWarning: Property dataset.label will be deprecated, please use g.ndata['label'] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/dgl/data/utils.py:288: UserWarning: Property dataset.train_mask will be deprecated, please use g.ndata['train_mask'] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
     ]
    }
   ],
   "source": [
    "g, features, labels, mask = load_cora_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2= GAT(g,\n",
    "          features.size()[1],\n",
    "          hidden_dim=8,\n",
    "          out_dim=7,\n",
    "          num_heads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 7])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net3(features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Epoch 00000 | Loss 1.9464 | Time(s) nan\n",
      "Epoch 00001 | Loss 1.9444 | Time(s) nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/dgl/data/utils.py:288: UserWarning: Property dataset.feat will be deprecated, please use g.ndata['feat'] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/dgl/data/utils.py:288: UserWarning: Property dataset.label will be deprecated, please use g.ndata['label'] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/dgl/data/utils.py:288: UserWarning: Property dataset.train_mask will be deprecated, please use g.ndata['train_mask'] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00002 | Loss 1.9425 | Time(s) nan\n",
      "Epoch 00003 | Loss 1.9405 | Time(s) 0.0844\n",
      "Epoch 00004 | Loss 1.9386 | Time(s) 0.0814\n",
      "Epoch 00005 | Loss 1.9366 | Time(s) 0.0809\n",
      "Epoch 00006 | Loss 1.9346 | Time(s) 0.0800\n",
      "Epoch 00007 | Loss 1.9327 | Time(s) 0.0789\n",
      "Epoch 00008 | Loss 1.9307 | Time(s) 0.0789\n",
      "Epoch 00009 | Loss 1.9287 | Time(s) 0.0797\n",
      "Epoch 00010 | Loss 1.9267 | Time(s) 0.0793\n",
      "Epoch 00011 | Loss 1.9247 | Time(s) 0.0795\n",
      "Epoch 00012 | Loss 1.9228 | Time(s) 0.0795\n",
      "Epoch 00013 | Loss 1.9208 | Time(s) 0.0790\n",
      "Epoch 00014 | Loss 1.9187 | Time(s) 0.0788\n",
      "Epoch 00015 | Loss 1.9167 | Time(s) 0.0787\n",
      "Epoch 00016 | Loss 1.9147 | Time(s) 0.0785\n",
      "Epoch 00017 | Loss 1.9127 | Time(s) 0.0785\n",
      "Epoch 00018 | Loss 1.9106 | Time(s) 0.0785\n",
      "Epoch 00019 | Loss 1.9086 | Time(s) 0.0782\n",
      "Epoch 00020 | Loss 1.9065 | Time(s) 0.0782\n",
      "Epoch 00021 | Loss 1.9044 | Time(s) 0.0783\n",
      "Epoch 00022 | Loss 1.9023 | Time(s) 0.0782\n",
      "Epoch 00023 | Loss 1.9002 | Time(s) 0.0784\n",
      "Epoch 00024 | Loss 1.8981 | Time(s) 0.0784\n",
      "Epoch 00025 | Loss 1.8960 | Time(s) 0.0782\n",
      "Epoch 00026 | Loss 1.8939 | Time(s) 0.0781\n",
      "Epoch 00027 | Loss 1.8917 | Time(s) 0.0782\n",
      "Epoch 00028 | Loss 1.8896 | Time(s) 0.0782\n",
      "Epoch 00029 | Loss 1.8874 | Time(s) 0.0787\n",
      "Epoch 00030 | Loss 1.8852 | Time(s) 0.0796\n",
      "Epoch 00031 | Loss 1.8830 | Time(s) 0.0798\n",
      "Epoch 00032 | Loss 1.8808 | Time(s) 0.0799\n",
      "Epoch 00033 | Loss 1.8786 | Time(s) 0.0797\n",
      "Epoch 00034 | Loss 1.8764 | Time(s) 0.0797\n",
      "Epoch 00035 | Loss 1.8741 | Time(s) 0.0799\n",
      "Epoch 00036 | Loss 1.8719 | Time(s) 0.0806\n",
      "Epoch 00037 | Loss 1.8696 | Time(s) 0.0810\n",
      "Epoch 00038 | Loss 1.8673 | Time(s) 0.0811\n",
      "Epoch 00039 | Loss 1.8650 | Time(s) 0.0811\n",
      "Epoch 00040 | Loss 1.8627 | Time(s) 0.0810\n",
      "Epoch 00041 | Loss 1.8603 | Time(s) 0.0809\n",
      "Epoch 00042 | Loss 1.8580 | Time(s) 0.0809\n",
      "Epoch 00043 | Loss 1.8556 | Time(s) 0.0809\n",
      "Epoch 00044 | Loss 1.8532 | Time(s) 0.0810\n",
      "Epoch 00045 | Loss 1.8509 | Time(s) 0.0813\n",
      "Epoch 00046 | Loss 1.8484 | Time(s) 0.0815\n",
      "Epoch 00047 | Loss 1.8460 | Time(s) 0.0817\n",
      "Epoch 00048 | Loss 1.8436 | Time(s) 0.0818\n",
      "Epoch 00049 | Loss 1.8411 | Time(s) 0.0820\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "g, features, labels, mask = load_cora_data()\n",
    "\n",
    "# create the model, 2 heads, each head has hidden size 8\n",
    "net = GAT(g,\n",
    "          in_dim=features.size()[1],\n",
    "          hidden_dim=8,\n",
    "          out_dim=7,\n",
    "          num_heads=2)\n",
    "\n",
    "# create optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "# main loop\n",
    "dur = []\n",
    "for epoch in range(50):\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    logits = net(features)\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    loss = F.nll_loss(logp[mask], labels[mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "    print(\"Epoch {:05d} | Loss {:.4f} | Time(s) {:.4f}\".format(\n",
    "        epoch, loss.item(), np.mean(dur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
