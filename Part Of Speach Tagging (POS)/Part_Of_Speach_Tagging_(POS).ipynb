{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHMEQn8KmUaq",
        "outputId": "0458b126-0709-4432-f62d-436088c9ba64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  He spoke confidently, running is good exercise.\n",
            "Recognized Tags:  ['He (NNP) spoke confidently, (RB), running (VBG) is good exercise.']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def rule_based_pos_tagging(sentence):\n",
        "    # Define lexical rules\n",
        "    lexical_rules = [\n",
        "        (r'\\b\\w+ly\\b', 'RB'),  # Adverbs ending in -ly\n",
        "        (r'\\b[A-Z][a-z]*\\b', 'NNP'),  # Proper nouns starting with a capital letter\n",
        "        (r'\\b\\w+ing\\b', 'VBG'),  # Gerunds or present participles\n",
        "    ]\n",
        "\n",
        "    # Define contextual rules\n",
        "    contextual_rules = [\n",
        "        (r'\\bhe\\b \\b\\w+\\b', 'NN'),  # Nouns following the pronoun \"he\"\n",
        "    ]\n",
        "\n",
        "    # Tokenize the sentence into words\n",
        "    words = sentence.split()\n",
        "\n",
        "    # Apply lexical rules\n",
        "    for rule in lexical_rules:\n",
        "        pattern, tag = rule\n",
        "        words = [re.sub(pattern, f'{word} ({tag})', word ) for word in words]\n",
        "\n",
        "    # Apply contextual rules\n",
        "    for rule in contextual_rules:\n",
        "        pattern, tag = rule\n",
        "        words = [re.sub(pattern, tag, ' '.join(words))]\n",
        "\n",
        "    return words\n",
        "\n",
        "# Example usage\n",
        "sentence = \"He spoke confidently, running is good exercise.\"\n",
        "tagged_sentence = rule_based_pos_tagging(sentence)\n",
        "print(\"Sentence: \", sentence)\n",
        "print(\"Recognized Tags: \", tagged_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Download the sample dataset from NLTK\n",
        "nltk.download('treebank')\n",
        "from nltk.corpus import treebank\n",
        "\n",
        "# Extract features and labels from the NLTK dataset\n",
        "def extract_features(word, prev_word):\n",
        "    return {\"word\": word, \"prev_word\": prev_word}\n",
        "\n",
        "data = [(word, pos) for (word, pos) in treebank.tagged_words()]\n",
        "features = [(extract_features(data[i][0], '' if i == 0 else data[i-1][0]), pos) for i, (word, pos) in enumerate(data)]\n",
        "\n",
        "# Split data into features and labels\n",
        "X = [features[i][0] for i in range(len(features))]\n",
        "y = [features[i][1] for i in range(len(features))]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize features using DictVectorizer\n",
        "vectorizer = DictVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Decision Tree classifier\n",
        "classifier = DecisionTreeClassifier()\n",
        "classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Predict POS tags for the test set\n",
        "y_pred = classifier.predict(X_test_vectorized)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    predicted = classifier.predict(X_test_vectorized[i])\n",
        "    actuall = y_test[i]\n",
        "    print(\"Predicted Tags: \", predicted)\n",
        "    print(\"Actuall Tages: \", actuall)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVBsdKgLmXd-",
        "outputId": "c2defe3f-3398-44ce-b771-64999fccd8a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Tags:  ['NNP']\n",
            "Actuall Tages:  NNP\n",
            "Predicted Tags:  [',']\n",
            "Actuall Tages:  ,\n",
            "Predicted Tags:  ['-NONE-']\n",
            "Actuall Tages:  -NONE-\n",
            "Predicted Tags:  ['NNP']\n",
            "Actuall Tages:  NNP\n",
            "Predicted Tags:  ['.']\n",
            "Actuall Tages:  .\n",
            "Predicted Tags:  ['IN']\n",
            "Actuall Tages:  IN\n",
            "Predicted Tags:  ['NNP']\n",
            "Actuall Tages:  NN\n",
            "Predicted Tags:  ['VB']\n",
            "Actuall Tages:  VB\n",
            "Predicted Tags:  ['$']\n",
            "Actuall Tages:  $\n",
            "Predicted Tags:  ['CC']\n",
            "Actuall Tages:  CC\n",
            "Accuracy: 0.86\n"
          ]
        }
      ]
    }
  ]
}